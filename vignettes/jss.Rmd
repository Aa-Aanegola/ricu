---
title:
  formatted: "\\pkg{ricu}: \\proglang{R}'s interface to ICU data"
  plain:     "ricu: R's interface for ICU data"
  short:     "\\pkg{ricu}: R meets ICU data"
author:
  - name: Nicolas Bennett
    affiliation: ETH Zürich
    address: >
      Seminar for Statistics
      Rämistrasse 101
      CH-8092 Zurich
    email: \email{nicolas.bennett@stat.math.ethz.ch}
  - name: Drago Plecko
    affiliation: ETH Zürich
    address: >
      Seminar for Statistics
      Rämistrasse 101
      CH-8092 Zurich
    email: \email{drago.plecko@stat.math.ethz.ch}
  - name: Ida-Fong Ukor
    affiliation: East Kent Hospitals
    address: >
      NHS University Foundation Trust
      William Harvey Hospital
      Kennington Road, Willesborough
      Ashford TN24 0LZ
    email: \email{idafong.ukor@nhs.net}
abstract: >
  The abstract of the article.
keywords:
  formatted: [medicine, intensive care, computational bioinformatics]
  plain:     [medicine, intensive care, computational bioinformatics]
preamble: >
  \usepackage{amsmath}
vignette: >
  %\VignetteIndexEntry{Accessing ICU data with R (Bennett & Plecko, JSS 2020)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
output: >
  if (packageVersion("rticles") < 0.5 || rmarkdown::pandoc_version() >= 2)
    rticles::jss_article else rmarkdown::html_vignette
documentclass: jss
bibliography: jss.bib
pkgdown:
  as_is: true
  extension: pdf
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ricu)
library(data.table)
library(forestmodel)
library(survival)
library(ggplot2)

srcs  <- c("mimic", "mimic_demo", "eicu", "eicu_demo", "hirid", "aumc")
avail <- is_data_avail(srcs)

srcs_avail <- function(x) all(avail[x])

if (!srcs_avail(srcs)) {

  msg <- paste(
    "Note: Examples in this vignette require that one or more of datasets",
    paste("`", srcs, "`", collapse = ", "), "are available. Chunks that",
    "depend on certain datasets will not be evaluated if the corresponding",
    "dataset is missing. In order to download and setup data, have a look at",
    "`?setup_src_data`."
  )
  msg <- paste(strwrap(msg), collapse="\n")
  message(msg)
}
```

# Introduction

Collection of electronic health records has seen a significant rise in the recent years \cite{evans2016}, opening up opportunities and providing the grounds for a large body of data-driven research oriented towards helping clinicians in decision-making and therefore improving patient care and health outcomes \cite{jiang2017}.

One example of a problem that has received much attention from the machine learning community is early prediction of sepsis in ICU \cite{desautels2016, nemati2018, futoma2017, kam2017}. Interestingly, there is evidence that a large proportion of the publications are based on the same dataset \cite{fleuren2019}, the Medical Information Mart for Intensive Care III (MIMIC-III) \cite{johnson2016}, which shows a systematic lack of external validation. Part of this problem might well be the lack of a computational infrastructure handling multiple datasets. The MIMIC-III dataset consists of 26 different tables containing about 20GB of data. While much work and care has gone into data preprocessing in order to provide a self-contained ready to use data resource with MIMIC-III, seemingly simple tasks such as computing a SOFA score for patients \citep{vincent1996}, remains a non trivial effort^[There is considerable heterogeneity in number of patients satisfying the Sepsis-3 criterion among studies investigating MIMIC-III. Reported Sepsis-3 prevalence ranges from 11.3% \cite{desautels2016}, over 23.9% \cite{nemati2018} and 25.4% \cite{wang2018}, up to 49.1% \cite{johnson2018}. While some of this variation may be explained by varying patient inclusion criteria, differences in label implementations must also contribute significantly.]. This is only exacerbated when aiming to co-integrate multiple different datasets of this form, spanning hospitals and even countries, in order to capture effects of differing practice and demographics.

The aim of the \pkg{ricu} package is to provide computational infrastructure allowing users to access complex research questions as easily as possible by providing a unified interface to a heterogeneous set of datasets. The package enables users to write dataset-agnostic code which can simplify implementation and shorten the necessary time prototyping code for different datasets. In its current form, the package handles four large-scale, publicly available intensive care databases out of the box: MIMIC-III from the Beth Israel Deaconess Medical Center in Boston, Massachusetts \cite{johnson2016}, the eICU Collaborative Research Database \cite{pollard2018}, containing data collected from 208 hospitals across the United States, HiRID from the Department of Intensive Care Medicine of the Bern University Hospital, Switzerland \cite{faltys2020} and AmsterdamUMCdb from the Amsterdam University Medical Center \cite{elbers2019}. Furthermore, \pkg{ricu} was designed with extensibility in mind such that adding further public and or private user-provided datasets is possible.

To our knowledge, infrastructure that provides a common interface to multiple such datasets is a novel contribution. While there have been efforts such as \cite{adibuzzaman2016} and \cite{wang2020} attempting to abstract away some specifics of a dataset, these have so far exclusively focused on MIMIC-III, the most popular of public ICU datsets and have not been designed with dataset interoperability in mind.

Given the somewhat narrow focus of the targeted datasets, combined with the fact that in some cases data is even extracted from identical systems, it may come as a surprise as to how heterogeneous the resulting datasets are. In MIMIC-III and HiRID, for example, time-stamps are reported as absolute times (albeit randomly shifted due to data privacy concerns), whereas eICU and AUMC use relative times (with origins being admission times). Furthermore, while relative times in eICU are reported in minutes, AUMC uses millisecond resolution. Another example, involves different types of patient identifiers and their use among datasets. Common to all is the notion on an ICU admission ID, but apart from that, the amount of available information varies. While ICU readmissions for a given patient can be identified in both eICU and MIMIC-III, this is not possible on either HiRID or AUMC. Similarly, individual patients can be identified on AUMC and MIMIC-III, but not on eICU or HiRID. In this sense, MIMIC-III is the most complete dataset of the four, but this comes with issues of its own: ID availability among tables varies, requiring extra processing steps for retrieving data across tables with common IDs.

The following sections serve to introduce \pkg{ricu} by first giving an overview of particularities of the four default dataset, followed by some implementation details on how datasets are stored and how external data sources can be made accessible by \pkg{ricu} (\ref{data_srcs}). The next section is concerned with ...

# Data sources {#data_srcs}

In order to make data available from different data sources, \pkg{ricu} provides abstractions using JSON-formatted configuration files and a set of S3 generic functions. This system is designed with extensibility in mind, allowing for incorporation of a wide variety of datasets. Provisions for several large-scale publicly available datasets in terms of required configuration information alongside class-specific implementations of the needed S3 generic functions are part of \pkg{ricu}, opening up access to theses datasets. Data itself, however, is not part of \pkg{ricu} but rather can be downloaded form the Internet using tools provided by \pkg{ricu}. While the datasets are publicly available, access has to be granted by the dataset creators individually. Three datasets, MIMIC-III, eICU and HiRID are hosted on PhysioNet \cite{goldberger2000}, access to which requires an [account](https://physionet.org/register/), while the fourth, AmsterdamUMCdb is currently distributed via a separate platform, requiring a [download link](https://amsterdammedicaldatascience.nl/#amsterdamumcdb).

For both MIMIC-III and eICU, small subsets of data are available as demo datasets that do not require credentialed access to PhysioNet. As the terms for distribution of those demo datasets are less restrictive, they can be made available as data packages \pkg{mimic.demo} and \pkg{eicu.demo}. Due to size constraints, however they are not available via CRAN, but can be installed from Github as

```{r demo-data, eval = FALSE}
install.packages(
  c("mimic.demo", "eicu.demo"),
  repos = "https://septic-tank.github.io/physionet-demo"
)
```

Provisions for datasets configured to be attached during package loading are made irrespectively of whether data is actually available. Upon first access of a dataset with some (or all) data missing, the user is asked for permission to download in interactive sessions and an error is thrown otherwise. Credentials can either be provided as environment variables (as `RICU_PHYSIONET_USER` and `RICU_PHYSIONET_PASS` for access to PhysioNet data, as well as `RICU_AUMC_TOKEN` for AmsterdamUMCdb) and if the corresponding variables are unset, user input is again required in interactive sessions. For non-interactive sessions, functionality is exported such that data can be downloaded and set up ahead of first access (see [setup_src_data()]), which requires the environment variables to be set or credentials to be passed as function arguments.

## Ready to use datasets

Contingent on being granted access by the data owners 4 large-scale ICU datasets collected from multiple hospitals in the US and Europe can be set up for access using \pkg{ricu} with minimal user intervention. Download requires a stable Internet connection as the amount of downloaded data ranges from 5 to 10 GB per dataset, as well as 50 to 100 GB of temporary disk storage for unpacking and preparing the data for efficient access. In terms of permanent storage, again 5 to 10 GB per dataset are required. Despite uncompressed sizes of 50 to 100 GB for some of the larger tables, memory requirements easily permit importing (and working with) these tables using Laptop class hardware as only subsets of rows are read at the time.

The following paragraphs serve to give quick introductions to the datasets to offer some guidance on where to start, outlining some strengths and weaknesses of each of the datasets. Especially the PhysioNet datasets [MIMIC-III](https://mimic.physionet.org/about/mimic/) and [eICU](https://eicu-crd.mit.edu/about/eicu/) offer good documentation on the respective websites.

### MIMIC-III
The [Medical Information Mart for Intensive Care III (MIMIC-III)](https://physionet.org/content/mimiciii/1.4/) represents the third iteration of the arguably most influential initiative for collecting and providing to the public large-scale ICU data. The initial MIMIC (at the time short for Multi-parameter Intelligent Monitoring for Intensive Care) data release dates back 20 years and contains data on roughly 100 patients recorded from patient monitors in the medical, surgical, and cardiac intensive care units of Boston's Beth Israel Hospital during the years 1992-1999 \cite{moody1996}. Building on lessons learnt and significantly broadened in scope, MIMIC-II was released 10 years after, now including data on almost 27,000 adult hospital admissions collected from ICUs of Beth Israel Deaconess Medical Center (BIDMC), a large (>500 bed) hospital affiliated with the Harvard Medical School with 77 critical care beds available, from 2001 to 2008 \cite{lee2011}.

Continuing the success of this storied line of ICU data releases, MIMIC-IV is just around the corner with a first development version having been released in summer 2020. Now including data of ICUs and emergency departments of BIDMC from the years 2008-2019, this iteration of MIMIC too is planned to be included with \pkg{ricu} as soon a first stable version is released.

The to-date most comprehensive iteration of MIMIC data releases, MIMIC-III, comprises de-identified health related data of roughly 46,000 patients admitted to critical care units of BIDMC during the years 2001-1012. Amounting to just over 61,000 individual ICU admission, data is available on demographics, routine vital sign measurements (at approximately 1 hour resolution), laboratory tests, medication, as well as critical care procedures, organized as a 26-table relational structure.

```{r mimic-tables, eval = srcs_avail("mimic")}
mimic
```

One thing of note from a data-organizational perspective is that a change in electronic health care systems occurred in 2008. Owing to this, roughly 48,000 ICU admissions spanning the years 2001 though 2008 are documented using the CareVue system, while for 2008 and onwards, data was extracted from the MetaVision system. Item identifiers differ between the two systems, requiring queries to consider both ID mappings (heart rate for example being available both as `itemid` number `211` for CareVue and `220045` for MetaVision) as does documentation of infusions and other procedures that are considered as input events (c.f. `inputevents_cv` and `inputevents_mv` tables). Especially with respect to such input event data, MetaVision data generally is of superior quality.

In terms of patient identifiers, MIMIC-III allows for identifying both individual patients (`subject_id`) across hospital admissions (`hadm_id`) and for connecting ICU (re-)admissions (`icustay_id`) to hospital admissions. Using the respective one-to-many relationships, \pkg{ricu} can retrieve patient data using any of the above IDs, irrespective of how the raw data is organized.

### eICU
Unlike the single-center focus of other datasets, the [eICU Collaborative Research Database](https://physionet.org/content/eicu-crd/2.0/) constitutes an amalgamation of data from critical care units of over 200 hospitals throughout the continental United States. Large-scale data collected via the Philips eICU program which provides telehealth infrastructure for intensive care units, is available from the Philips eICU Research Institute (eRI), albeit neither publicly nor freely. Only data corresponding to roughly 200,000 ICU admissions, sampled from a larger population of over 3 million ICU admissions and stratified by hospital, is being made available via PhysioNet. Patients with discharge dates in 2014 or 2015 were considered, with stays in low acuity units being removed.

```{r eicu-tables, eval = srcs_avail("eicu")}
eicu
```

The data is organized into 31 tables and includes patient demographics, routine vital signs, laboratory measurements, medication administrations, admission diagnoses, as well as treatment information. Owing to the wide range of hospitals participating in this data collection initiative, spanning small, rural, non-teaching health centers with fewer than 100 beds to large teaching hospitals with an excess of 500 beds, there is heterogeneity in data availability. Even if data is being recorded at the bedside it might end up missing from the eICU dataset due to technical limitations of the collection process. As for patient identifiers, while it is possible to link ICU admissions corresponding to the same hospital stay, it is not possible to identify patients across hospital stays.

Data resolution varies considerably over included variables. The `vitalperiodic` table stands out as one of the few examples of a *wide* table organization, as opposed to the *long* presentation of most other tables containing patient measurement data, following an entity–attribute–value model instead of laying out variables as columns. The average time step in `vitalperiodic` is around 5 minutes, but data missingness ranges from around 1% for heart rate and pulse oximetry to around 80-90% for blood pressure measurements, therefore giving approximately hourly resolution.

### HiRID
Developed for early prediction of circulatory failure \cite{hyland2020}, the [high time resolution ICU dataset (HiRID)](https://physionet.org/content/hirid/1.0/) contains data on almost of 34,000 admissions to the Department of Intensive Care Medicine of the Bern University Hospital, Switzerland, an interdisciplinary 60-bed unit. Given the clear focus on a concrete application during data collection, this dataset is the most limited in terms of breadth of available information, which is also reflected in a comparatively simple data layout comprising only 5 tables.

```{r hirid-tables, eval = srcs_avail("hirid")}
hirid
```

Collected during the period of January 2008 through June 2016, roughly 700 distinct variables covering routine vital signs, diagnostic test results and treatment parameters are available with variables monitored at the bedside being recorded with two minute time resolution. In terms of demographic information and patient identifier systems, however the data is limited. It is not possible to identify ICU admissions corresponding to individual patients and apart from patient age, sex, weight and height, very little information is available to characterize patients. There is no medical history, no admission diagnoses, no mortality information, no unstructured patient data and no information on patient discharge. Furthermore, data on body fluid sampling has been omitted, complicating for example the construction of a Sepsis-3 label \citep{singer2016}.

The data is available in three states: as raw data and in preprocessed form, with preprocessed data being represented by two intermediary pipeline stages from \cite{hyland2020}. While \pkg{ricu} focuses exclusively on raw data, the *merged* stage represents a selection of variables that were deemed most predictive for determining circulatory failure, which are then merged into 18 meta-variables, representing different clinical concepts. Time stamps in *merged* data are left unchanged, yielding irregular time series, whereas for the *imputed* stage, data is down-sampled to a 5 minute grid and missing values are imputed using a scheme discussed in \cite{hyland2020}.

### AmsterdamUMCdb
As a second European dataset, also focusing on increased time-resolution over the US datasets, [AmsterdamUMCdb](https://amsterdammedicaldatascience.nl/#amsterdamumcdb) has been made available in late 2019, containing data on over 23,000 intensive care unit and high dependency unit admissions of adult patients during the years 2003 through 2016. The department of Intensive Care at Amsterdam University Medical Center is a mixed medical-surgical ICU with up to 32 bed ICU and 12 bed high dependency units with an average of 1000-2000 yearly admission. Covering middle ground between the US datasets and HiRID in terms if breadth of included data, while providing a maximal time-resolution of 1 minute, AmsterdamUMCdb constitutes a well organized high quality ICU data resource organized as 7-table relational structure.

```{r aumc-tables, eval = srcs_avail("aumc")}
aumc
```

A slightly different approach to data anonymization was chosen for this dataset, leading to having demographic information such as patient weight, height and age only available as binned variables. Apart from this, there is information on patient origin, mortality, admission diagnoses, as well as numerical measurements including vital parameters, lab results, outputs from drains and catheters (in `numericitems`), information on administered medication (in `drugitems`), and other medical procedures (see `processitems` and `procedureorderitems`). In terms of patient identifiers, it is possible to link ICU admissions corresponding to the same individual, but it is not possible to identify separate hospital admissions.

## Implementation details

Every dataset is represented by an environment with class attributes and associated metadata objects stored as object attributes to that environment. Dataset environments all inherit from `src_env` and from any number of class names constructed from data source name(s) with a suffix `_env` attached. The environment representing MIMIC-III, for example inherits from `src_env` and `mimic_env`, while the corresponding demo dataset inherits from `src_env`, `mimic_env` and `mimic_demo_env`. These sub-classes are later used for adapting the process of data loading to particularities of individual datasets.

A `src_env` contains an active binding per contained table, which returns a `src_tbl` object representing the requested table after having checked that the required data is locally available (and querying the user for download if not). As is the case for `src_env` objects, `src_tbl` object inherit from additional classes such that certain per-dataset behavior can be customized. The `admissions` table of the MIMIC-III demo dataset for example inherits from `mimic_demo_tbl` and `mimic_tbl` (alongside classes `src_tbl` and `prt`).

```{r mimic-adm, eval = srcs_avail("mimic_demo")}
mimic_demo$admissions
```

Powered by the \pkg{prt} package, `src_tbl` objects represent tabular data stored as a single or row-partitioned into multiple binary files created by \pkg{fst} \citep{klik2020}. In addition to standard subsetting, `prt` objects can be subsetted via the base R S3 generic function `subset()` and using non-standard evaluation:

```{r mimic-sub, eval = srcs_avail("mimic_demo")}
subset(mimic_demo$admissions, subject_id > 44000, language:ethnicity)
```

This syntax makes it possible to read row-subsets of *long* tables into memory with little memory overhead. While terseness of such an API does introduce potential ambiguity, this is mostly overcome by using the tidy eval framework provided by \pkg{rlang} \citep{wickham2020}:

```{r mimic-tidy, eval = srcs_avail("mimic_demo")}
subject_id <- 44000:45000
subset(mimic_demo$admissions, .data$subject_id %in% .env$subject_id,
       subject_id:dischtime)
```

By using so-called pronouns (`.data` and `.env`), the distinction between a name referring to an object within the context of the data and an object within the context of the calling environment can readily be made.

### Data source configuration

Data source environments (and corresponding `src_tbl`) are constructed from source configuration objects, list-based structures, inheriting from `src_cfg` and from any number of data source-specific class names with suffix `_cfg` appended in the same way as with `src_env` objects as explained above. The exported function `load_src_cfg()` reads a JSON formatted file using \pkg{jsonlite} \citep{ooms2014}, and creates `src_cfg` and therein contained objects.

```{r mimic-cfg}
cfg <- load_src_cfg("mimic_demo")
str(cfg, max.level = 2L, width = 70L)
mi_cfg <- cfg[["mimic_demo"]]
```

In addition to required fields `name` and `prefix` (used as class prefix as explained above), as well as further arbitrary fields (`url` in this case), several additional configuration objects are part of `src_cfg`.

#### ID configuration

An `id_cfg` object contains an ordered set of key-value pairs representing patient ID systems in a dataset. An implicit assumption currently is that a given patient ID system is used consistently throughout a dataset, meaning that for example an ICU stay ID is always referred to by the same name throughout all tables containing a corresponding column. Owing to the relational origins of these datasets this has been fulfilled in all instances encountered so far. In MIMIC-III, ID systems

```{r mimic-ids}
as_id_cfg(mi_cfg)
```

are available, allowing for identification of individual patients, their (potentially multiple) hospital admissions over the course of the years and their corresponding ICU admissions (as well as potential re-admissions). Ordering corresponds to cardinality: moving to larger values implies moving along a one-to-many relationship. This information is used in data-loading, whenever the target ID system is not contained in the raw data.

#### Default column configuration

Again used in data-loading, this per-table set of key-value pairs specifies column defaults as `col_cfg` object.

```{r mimic-col}
as_col_cfg(mi_cfg)
```

Each table may for example have a default `index_var`, i.e. a column that is used to define an ordering in time over rows, or a default set of `time_vars`, which will be treated as time variables (important for converting between ID systems for example), but not as time-series indices. For the `admissions` table, for example, there is no default `index_var` defined, but a total of 5 columns are considered to be time variables, while for the `inputevents_mv`, one of the 4 available time variables makes sense as default index variable. During data-loading, there per-table defaults can be overridden and they mainly serve to reduce verbosity of calls in data-loading. In addition to the presently available column defaults, arbitrary further keys can be added.

#### Table configuration

Finally, `tbl_cfg` objects are used during the initial set-up of a data source. In order to create a representation of a table that is accessible from \pkg{ricu} from raw data, several key pieces of information are required:

* File name(s): In the simplest case, a single file corresponds to a single table. Other scenarios that have been encountered include tables partitioned into multiple files and .tar archives containing multiple tables.

* Column specification: For each column, the expected data type has to be known, as well as a pair of names, one corresponding to the raw data column name and one corresponding to the column name to be used within \pkg{ricu}.

* (Optional) number of rows: Used as sanity check whenever available.

* (Optional) partitioning information: For very *long* tables it can be useful to specify a row-partitioning. This currently is only possible by applying a vector of break points to a single numeric columns, thereby defining a grouping.

```{r mimic-tbl}
as_tbl_cfg(mi_cfg)
```

For the `chartevents` table of the MIMIC-III demo dataset, for example, rows are partitioned into 2 groups and the expected number of rows is unknown as this is missing from the corresponding `tbl_cfg` object.

### Data source set-up

In order to make a dataset accessible to \pkg{ricu}, three steps are necessary, each handled by an exported S3 generic function: `download_scr()`, `import_src()` and `attach_src()`. While the first two steps, download and import are one-time procedures, attaching is carried out every time the package namespace is loaded. By default, all data sources known to \pkg{ricu} are configured to be attached and in case some (or all) data is missing for a given data source, the missing data is downloaded and imported on first access (and pending user consent). For download to run through without user interaction, several environment variables can be configured:

* `RICU_PHYSIONET_USER`/`RICU_PHYSIONET_PASS`: PhysioNet user name and password with access to the requested dataset.
* `RICU_AUMC_TOKEN`: Download token, extracted from the download URL received when requesting data access.

If any of the required access credentials are not available as environment variables, the user is queried in interactive sessions. Each of the datasets requires 5-10 GB disk space for permanent storage. In addition to that, 50-75 GB of temporary dist storage are required during download and import of any of the datasets, roughly corresponding to the respective maximum table sizes (uncompressed). Memory requirements are kept low by performing all set-up operations only on subsets of rows at the time, such that laptop-class hardware is sufficient for handling these datasets.

Further environment variable can be set to customize certain aspect of \pkg{ricu} data handling:

* `RICU_DATA_PATH`: Data storage location (can be queried by calling `data_dir()`).
* `RICU_CONFIG_PATH`: Comma-separated paths to directories containing configuration files (in addition to the default location; retrievable using `config_paths()`).
* `RICU_SRC_LOAD`: Comma-separated data source names that are set up for being automatically attached on namespace loading (the current set of data sources is available as `auto_attach_srcs()`).

After successful data download, importing prepares tables for efficient random row-access, for which the raw data format (.csv) is not well suited. Tables are read in using \pkg{readr} \citep{hester2020}, potentially partitioned row-wise, and re-saved using \pkg{fst}. Finally, attaching a dataset creates a corresponding `src_env` object which together with associated meta-data is used by \pkg{ricu} to run queries against the data.

### Data loading

The lowest level of data access is direct subsetting of `src_tbl` objects as shown at the start of this section (\ref{implementation-details}). Building on that, several S3 generic functions successively homogenize data representations, starting with `load_src()`, which provides a string-based interface to `subset()` for all but the row-subsetting expression (intended for non-interactive use).

```{r load-src, eval = srcs_avail("mimic_demo")}
load_src("admissions", "mimic_demo", subject_id > 44000,
         c("subject_id", "hadm_id","admittime", "dischtime"))
```

As data sources differ in their representation of time-stamps, a next step in data homogenization is to converge to a common format: the time difference to the origin time-point of a given ID system.

```{r load-dt, eval = srcs_avail("mimic_demo")}
load_difftime("admissions", "mimic_demo", subject_id > 44000,
              c("subject_id", "hadm_id", "admittime", "dischtime"))
```

The function `load_difftime()` is expected to return timestamps as base R `difftime` vectors (using `mins` as time unit). The argument `id_hint` can be used to specify a preferred ID system but if not available in raw data, `load_difftime()` will return data using the ID system with highest cardinality. In the above example, if `icustay_id` were requested, data would be returned using `hadm_id`, whereas the a `subject_id` request would be honored.

Building on `load_difftime()` functionality, `load_id()` (and analogously `load_ts()`) returns an `id_tbl` (or `ts_tbl`) object with the requested ID system (passed as `id_var` argument). This uses raw data IDs if available or calls `change_id()` in order to convert to the desired IDs. Similarly, where `load_difftime()` returns data with fixed time interval, `load_id()` allows for arbitrary time intervals (using `change_interval()`).

```{r load-id, eval = srcs_avail("mimic_demo")}
load_id("admissions", "mimic_demo", subject_id > 44000,
        cols = c("admittime", "dischtime"), id_var = "hadm_id")
```

## Adding external datasets

# Data concepts

In this Section we go over the categories of data useful for research problems related to intensive care medicine. The categories we define are fairly broad and somewhat loosely defined, as this is not the main focus of the manuscript.

## Physiological data
Labs, vitals. Could introduce the \code{ts_tbl} here.

## Treatment-related information
Antibiotics, vasopressors, mechanical ventilation... could introduce the \code{win_tbl} here.

## Co-morbidities

Based on ICD-9 codes. Should enable the extraction of co-morbidities used for the Charlson and Elixhauser scores.

## Admission diagnoses
Categorizing into surgical, non-surgical and other might be sufficient for now.

## Patient information
Age, gender, other demograpichs, patient stay information.

## Outcomes
Death outcome, prolonged ICU stay outcome.

## Implementation details

# Examples

We focus on two simple examples with which we try to cover most of the data types described in Section \ref{implementation-details}.

## Lactate and mortality
The first example we look at is the association of lactate levels and mortality. This problem has been studied before and it is widely accepted that both static and dynamic lactate indices are associated with increased mortality \citep{haas2016, nichol2011, van2013}. We quickly look at how one might fit a time-varying proportional hazards Cox model \citep{therneau2000, therneau2015} in order to investigate this problem. We additionally include the Sequential Organ Failure Assessment (SOFA) score \citep{vincent1996} as a general predictor of illness severity.

```{r time_cox_model, eval = srcs_avail("mimic_demo")}
last_event <- function(x) c(rep(0, length(x)-1), max(x))
# data loading
tbl <- load_concepts(c("lact", "death", "sofa"), "mimic_demo",
                     verbose = FALSE)
tbl <- tbl[, c(meta_vars(tbl), "lact", "sofa", "death"), with = FALSE]
tbl <- tbl[, lact := nafill(lact, "locf")]
tbl <- tbl[, lact := nafill(lact, fill = 1)]
tbl[, event := as.integer(sum(death, na.rm = TRUE) > 0), by = c(id_vars(tbl))]
tbl[, event := last_event(event), by = c(id_vars(tbl))]
tbl[, next_charttime := charttime+1L]
# model fitting
cox_time_mod <- coxph(
  Surv(charttime, next_charttime, event) ~ lact + sofa,
  data = tbl
)
```

We visualize the results of the model

```{r cox_plot, echo = FALSE, warning = FALSE, message = FALSE}
forest_model(cox_time_mod)
```

A simple exploration already shows that the increased values of lactate are associated with mortality, even after adjusting for the SOFA score.

## Diabetes and insulin treatment
The next example we turn to covers the usage of co-morbidities and treatment related information. We look at the amount of insulin administered to patients in the first 24 hours from their ICU admission. In particular, we investigate if patients who are diabetic receive more insulin in the first day of their stay. For this we create two concepts: `ins24`, a binned variable representing the cumulative amount of insulin administered within the first 24 hours of an ICU admission, and `diab`, a logical variable encoding diabetes co-morbidity.

As there already is a concept available, capable of retrieving raw insulin administration, `ins24` can be implemented as `rec_cncpt`, making sure that `ins` is loaded with aggregation set to `sum()` and injecting the callback function `ins_cb()` into the loading process. The callback function takes care of the pre-processing steps outlined above: first data is subsetted to fall into the the first 24 hours of ICU admissions, followed by binning of summed values.

```{r ins24, eval = srcs_avail("mimic_demo")}
ins_breaks <- c(0.01, 10, 20, 30, 40)

ins_cb <- function(ins, ...) {

  day_one <- function(x) x >= hours(0L) & x <= hours(24L)

  idx_var <- index_var(ins)
  ids_var <- id_vars(ins)

  ins <- ins[day_one(get(idx_var)), list(ins24 = sum(ins)),
             by = c(ids_var)]
  ins <- ins[, ins24 := list(
             .bincode(ins24, breaks = c(-Inf, ins_breaks, Inf)) - 1)]

  ins
}

ins24 <- load_dictionary("mimic_demo", "ins")
ins24 <- concept("ins24", ins24, "insulin in first 24h", aggregate = "sum",
                 callback = ins_cb, target = "id_tbl", class = "rec_cncpt")
```

The binary diabetes concept can for example be implemented as `lgl_cncpt`, for which ICD-9 codes are matched using a regular expression. As we're not only interested in retrieving diabetic patients, a `col_itm` is more suited for data retrieval over an `rgx_itm` and for creating the required callback function that produces a logical vector we can use `transform_fun()` coupled with a function like `grep_diab()`. The two concepts are then combined using `c()` and loaded via `load_concepts()`.

```{r diab, eval = srcs_avail("mimic_demo")}
grep_diab <- function(x) grepl("^250\\.?[0-9]{2}$", x)

diab  <- item("mimic_demo", table = "diagnoses_icd",
              callback = transform_fun(grep_diab), class = "col_itm")
diab  <- concept("diab", diab, "diabetes", target = "id_tbl",
                 class = "lgl_cncpt")

dat <- load_concepts(c(ins24, diab), id_type = "icustay", verbose = FALSE)
dat <- replace_na(dat, 0, cols = "ins24")
dat
```

After this, we can visualize the difference between the two groups with a histogram:

```{r diabetes_visualize, echo = FALSE, eval = srcs_avail("mimic_demo")}

bin_labels <- function(breaks, unit, lower0 = TRUE) {

  x_labels <- sapply(1:(length(breaks)-1),
    function(x) paste0("[", breaks[x], "-", breaks[x+1], "]")
  )

  first_label <- paste0("< ", breaks[1])
  if (lower0) first_label <- paste0("[0-", breaks[1], "]")
  x_labels <- c(first_label, x_labels, paste0("> ", breaks[length(breaks)]))

  paste(x_labels, unit)
}

ggplot(dat, aes(x = ins24, fill = diab, colour = diab)) +
  geom_histogram(aes(y = ..count.. / sum(..count..)), alpha = 0.75,
                 position = "dodge", bins = 1 + length(ins_breaks)) +
  xlab("Amount of administered insulin in first 24h of ICU stay") +
  ylab("Proportion of patients") +
  scale_x_continuous(labels = bin_labels(ins_breaks, "units"),
                     breaks = c(0, seq_along(ins_breaks))) +
  theme_minimal(10) +
  theme(legend.position = c(0.7, 0.7),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        legend.text = element_text(size = 12),
        legend.title = element_text(size = 16))
```

The plot might suggest that diabetic patients do receive more insulin that non-diabetic patients, in the first day of ICU stay.
